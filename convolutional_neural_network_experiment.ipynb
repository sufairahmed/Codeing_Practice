{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12n6UCiQARZhNQXaBSpIiufD_kRkNx4U2",
      "authorship_tag": "ABX9TyPpKREPLpEAPFM4653Zb+D7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufairahmed/ML_Practice/blob/master/convolutional_neural_network_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6m09h0dEu2V"
      },
      "source": [
        "#convolutional_neural_network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0hcndjmFBsv"
      },
      "source": [
        "import tensorflow as tf \r\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aYnxrZsSFTfo",
        "outputId": "3718eb2f-adec-4b65-96a4-2b1c223bfdc5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpE3NQHNFYRQ"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrfr4b02FceH"
      },
      "source": [
        "### Preprocessing Training set by keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ep9s1sUFbHw",
        "outputId": "c678034c-d2af-43c9-9c3c-7fafeacaa337"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Machine Learning A-Z (Codes and Datasets)/Part 8 - Deep Learning/Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/training_set',\r\n",
        "                                                 target_size = (64, 64),\r\n",
        "                                                 batch_size = 32,\r\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 621 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzYqoG4GhxB"
      },
      "source": [
        "### Preprocessing Test seet by keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckmuPkZKGoY7",
        "outputId": "b2b92b4b-1300-4da4-84dd-e0f492610b50"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Machine Learning A-Z (Codes and Datasets)/Part 8 - Deep Learning/Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/test_set',\r\n",
        "                                            target_size = (64, 64),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2006 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UWrrn6iGuZw"
      },
      "source": [
        "##Building CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGc7n4wOG1ww"
      },
      "source": [
        "###Installing the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_DQg3mOG5sX"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXoEAyU8HMPg"
      },
      "source": [
        "###Step_1: Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbm84sqMGydp"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xhXeD7VHZHW"
      },
      "source": [
        "###Step_2:Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M7voFARHchR"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOlsX6YHrPX"
      },
      "source": [
        "###Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWml4SQgHswp"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsiG7wUgHf1_"
      },
      "source": [
        "###Step_3:Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIHlwFnGHl0R"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23x-r3cbH4Lf"
      },
      "source": [
        "###Step_4:Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3QEpSvgH8Q0"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpgSLAnIATL"
      },
      "source": [
        "###Step_5:Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jQJWFRmIFe3"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCu2CEWII_v"
      },
      "source": [
        "##Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBNTIIggIRNo"
      },
      "source": [
        "###Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYroMbsqIMRH"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHf7XG5hIYk4"
      },
      "source": [
        "###Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpdKXqQFIaeI",
        "outputId": "c7ddf420-fee3-462b-f66e-aea5c58840ac"
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "20/20 [==============================] - 16s 812ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 22.3336 - val_accuracy: 0.5015\n",
            "Epoch 2/25\n",
            "20/20 [==============================] - 16s 785ms/step - loss: 1.0481e-10 - accuracy: 1.0000 - val_loss: 27.5819 - val_accuracy: 0.5015\n",
            "Epoch 3/25\n",
            "20/20 [==============================] - 16s 783ms/step - loss: 5.2833e-13 - accuracy: 1.0000 - val_loss: 28.4453 - val_accuracy: 0.5015\n",
            "Epoch 4/25\n",
            "20/20 [==============================] - 16s 778ms/step - loss: 2.8429e-12 - accuracy: 1.0000 - val_loss: 28.5719 - val_accuracy: 0.5015\n",
            "Epoch 5/25\n",
            "20/20 [==============================] - 16s 787ms/step - loss: 2.7086e-12 - accuracy: 1.0000 - val_loss: 28.5895 - val_accuracy: 0.5015\n",
            "Epoch 6/25\n",
            "20/20 [==============================] - 16s 784ms/step - loss: 2.8993e-11 - accuracy: 1.0000 - val_loss: 28.5919 - val_accuracy: 0.5015\n",
            "Epoch 7/25\n",
            "20/20 [==============================] - 16s 777ms/step - loss: 1.1091e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 8/25\n",
            "20/20 [==============================] - 16s 780ms/step - loss: 7.4966e-11 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 9/25\n",
            "20/20 [==============================] - 16s 782ms/step - loss: 6.1520e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 10/25\n",
            "20/20 [==============================] - 16s 783ms/step - loss: 1.5621e-11 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 11/25\n",
            "20/20 [==============================] - 16s 776ms/step - loss: 2.7129e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 12/25\n",
            "20/20 [==============================] - 16s 780ms/step - loss: 9.7617e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 13/25\n",
            "20/20 [==============================] - 16s 781ms/step - loss: 8.8556e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 14/25\n",
            "20/20 [==============================] - 16s 785ms/step - loss: 3.5882e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 15/25\n",
            "20/20 [==============================] - 16s 786ms/step - loss: 1.4958e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 16/25\n",
            "20/20 [==============================] - 16s 816ms/step - loss: 1.5618e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 17/25\n",
            "20/20 [==============================] - 16s 790ms/step - loss: 3.6922e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 18/25\n",
            "20/20 [==============================] - 16s 787ms/step - loss: 5.1186e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 19/25\n",
            "20/20 [==============================] - 16s 779ms/step - loss: 8.4877e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 20/25\n",
            "20/20 [==============================] - 16s 796ms/step - loss: 1.2674e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 21/25\n",
            "20/20 [==============================] - 16s 797ms/step - loss: 5.3669e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 22/25\n",
            "20/20 [==============================] - 16s 790ms/step - loss: 2.9163e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 23/25\n",
            "20/20 [==============================] - 16s 784ms/step - loss: 4.5948e-12 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 24/25\n",
            "20/20 [==============================] - 16s 787ms/step - loss: 3.4186e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n",
            "Epoch 25/25\n",
            "20/20 [==============================] - 16s 795ms/step - loss: 7.5221e-13 - accuracy: 1.0000 - val_loss: 28.5922 - val_accuracy: 0.5015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1442b15ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK2iiexWIfpQ"
      },
      "source": [
        "##Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFj6EjK4Ihst"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "test_image = image.load_img('/content/drive/MyDrive/Colab Notebooks/Machine Learning A-Z (Codes and Datasets)/Part 8 - Deep Learning/Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = cnn.predict(test_image)\r\n",
        "training_set.class_indices\r\n",
        "if result[0][0] == 1:\r\n",
        "  prediction = 'dog'\r\n",
        "else:\r\n",
        "  prediction = 'cat'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSFpyVhaJ3wR",
        "outputId": "40583ee4-465a-43d7-abcd-01e7f14f656c"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}